{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# NOTEBOOK 5: PERFORMANCE OPTIMIZATION AND DEPLOYMENT\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "from sklearn.metrics import precision_recall_curve, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"üöÄ NOTEBOOK 5: PERFORMANCE OPTIMIZATION AND DEPLOYMENT\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Load best model and data\n",
        "print(\"üì• Loading best model and data...\")\n",
        "best_model = joblib.load('model_ensemble.pkl')  # Assuming ensemble is best\n",
        "X_train_scaled = joblib.load('X_train_scaled.pkl')\n",
        "X_test_scaled = joblib.load('X_test_scaled.pkl')\n",
        "y_train = joblib.load('y_train.pkl')\n",
        "y_test = joblib.load('y_test.pkl')\n",
        "\n",
        "print(f\"Training set: {X_train_scaled.shape}\")\n",
        "print(f\"Test set: {X_test_scaled.shape}\")\n",
        "\n",
        "# THRESHOLD OPTIMIZATION FOR MAXIMUM RECALL\n",
        "print(\"\\nüéØ THRESHOLD OPTIMIZATION FOR MAXIMUM RECALL\")\n",
        "\n",
        "# Get probabilities from best model\n",
        "y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Find optimal threshold for target recall\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "\n",
        "# Find threshold that gives us at least 75% recall\n",
        "target_recall = 0.75\n",
        "optimal_threshold_idx = np.argmax(recall >= target_recall)\n",
        "optimal_threshold = thresholds[optimal_threshold_idx] if optimal_threshold_idx < len(thresholds) else 0.3\n",
        "\n",
        "print(f\"üîç Threshold Analysis:\")\n",
        "print(f\"  ‚Ä¢ Default threshold (0.5): Recall = {recall[np.argmax(recall >= 0.5)]:.3f}\")\n",
        "print(f\"  ‚Ä¢ Optimal threshold for {target_recall*100}% recall: {optimal_threshold:.3f}\")\n",
        "\n",
        "# Apply optimized threshold\n",
        "y_pred_optimized = (y_pred_proba >= optimal_threshold).astype(int)\n",
        "\n",
        "# Calculate optimized metrics\n",
        "optimized_cm = confusion_matrix(y_test, y_pred_optimized)\n",
        "tn_opt, fp_opt, fn_opt, tp_opt = optimized_cm.ravel()\n",
        "\n",
        "optimized_recall = tp_opt / (tp_opt + fn_opt) if (tp_opt + fn_opt) > 0 else 0\n",
        "optimized_precision = tp_opt / (tp_opt + fp_opt) if (tp_opt + fp_opt) > 0 else 0\n",
        "optimized_f1 = 2 * (optimized_precision * optimized_recall) / (optimized_precision + optimized_recall) if (optimized_precision + optimized_recall) > 0 else 0\n",
        "\n",
        "print(f\"\\nüìä OPTIMIZED PERFORMANCE:\")\n",
        "print(f\"  ‚Ä¢ Threshold: {optimal_threshold:.3f}\")\n",
        "print(f\"  ‚Ä¢ Recall:    {optimized_recall:.3f} ({optimized_recall*100:.1f}% of leavers detected)\")\n",
        "print(f\"  ‚Ä¢ Precision: {optimized_precision:.3f}\")\n",
        "print(f\"  ‚Ä¢ F1-Score:  {optimized_f1:.3f}\")\n",
        "print(f\"  ‚Ä¢ True Positives:  {tp_opt}\")\n",
        "print(f\"  ‚Ä¢ False Negatives: {fn_opt}\")\n",
        "\n",
        "# BUSINESS IMPACT ANALYSIS\n",
        "print(f\"\\nüí∞ BUSINESS IMPACT ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Cost assumptions\n",
        "AVERAGE_REPLACEMENT_COST = 50000\n",
        "TRAINING_COST_PER_EMPLOYEE = 5000\n",
        "\n",
        "# Calculate business impact with optimized model\n",
        "risk_scores_optimized = (y_pred_proba >= optimal_threshold).astype(int)\n",
        "high_risk_employees = risk_scores_optimized.sum()\n",
        "\n",
        "# Assuming 70% of identified high-risk employees can be retained with interventions\n",
        "retention_success_rate = 0.70\n",
        "potential_retentions = int(high_risk_employees * retention_success_rate)\n",
        "\n",
        "# Cost savings calculation\n",
        "cost_savings = potential_retentions * AVERAGE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "dWgd3FbBTeRS",
        "outputId": "4a960085-139a-4508-d8fd-f56c94120d12"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ NOTEBOOK 5: PERFORMANCE OPTIMIZATION AND DEPLOYMENT\n",
            "==================================================\n",
            "üì• Loading best model and data...\n",
            "Training set: (1176, 30)\n",
            "Test set: (294, 30)\n",
            "\n",
            "üéØ THRESHOLD OPTIMIZATION FOR MAXIMUM RECALL\n",
            "üîç Threshold Analysis:\n",
            "  ‚Ä¢ Default threshold (0.5): Recall = 1.000\n",
            "  ‚Ä¢ Optimal threshold for 75.0% recall: 0.010\n",
            "\n",
            "üìä OPTIMIZED PERFORMANCE:\n",
            "  ‚Ä¢ Threshold: 0.010\n",
            "  ‚Ä¢ Recall:    1.000 (100.0% of leavers detected)\n",
            "  ‚Ä¢ Precision: 0.160\n",
            "  ‚Ä¢ F1-Score:  0.276\n",
            "  ‚Ä¢ True Positives:  47\n",
            "  ‚Ä¢ False Negatives: 0\n",
            "\n",
            "üí∞ BUSINESS IMPACT ANALYSIS\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'AVERAGE' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2784079666.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;31m# Cost savings calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0mcost_savings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpotential_retentions\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mAVERAGE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'AVERAGE' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86cdb145",
        "outputId": "9da80d7d-e42d-4f91-a73b-0d4c46b9f0d0"
      },
      "source": [
        "\n",
        "# =============================================================================\n",
        "# NOTEBOOK 5: PERFORMANCE OPTIMIZATION AND DEPLOYMENT\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "from sklearn.metrics import precision_recall_curve, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"üöÄ NOTEBOOK 5: PERFORMANCE OPTIMIZATION AND DEPLOYMENT\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Load best model and data\n",
        "print(\"üì• Loading best model and data...\")\n",
        "best_model = joblib.load('model_ensemble.pkl')  # Assuming ensemble is best\n",
        "X_train_scaled = joblib.load('X_train_scaled.pkl')\n",
        "X_test_scaled = joblib.load('X_test_scaled.pkl')\n",
        "y_train = joblib.load('y_train.pkl')\n",
        "y_test = joblib.load('y_test.pkl')\n",
        "\n",
        "print(f\"Training set: {X_train_scaled.shape}\")\n",
        "print(f\"Test set: {X_test_scaled.shape}\")\n",
        "\n",
        "# THRESHOLD OPTIMIZATION FOR MAXIMUM RECALL\n",
        "print(\"\\nüéØ THRESHOLD OPTIMIZATION FOR MAXIMUM RECALL\")\n",
        "\n",
        "# Get probabilities from best model\n",
        "y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Find optimal threshold for target recall\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "\n",
        "# Find threshold that gives us at least 75% recall\n",
        "target_recall = 0.75\n",
        "optimal_threshold_idx = np.argmax(recall >= target_recall)\n",
        "optimal_threshold = thresholds[optimal_threshold_idx] if optimal_threshold_idx < len(thresholds) else 0.3\n",
        "\n",
        "print(f\"üîç Threshold Analysis:\")\n",
        "print(f\"  ‚Ä¢ Default threshold (0.5): Recall = {recall[np.argmax(recall >= 0.5)]:.3f}\")\n",
        "print(f\"  ‚Ä¢ Optimal threshold for {target_recall*100}% recall: {optimal_threshold:.3f}\")\n",
        "\n",
        "# Apply optimized threshold\n",
        "y_pred_optimized = (y_pred_proba >= optimal_threshold).astype(int)\n",
        "\n",
        "# Calculate optimized metrics\n",
        "optimized_cm = confusion_matrix(y_test, y_pred_optimized)\n",
        "tn_opt, fp_opt, fn_opt, tp_opt = optimized_cm.ravel()\n",
        "\n",
        "optimized_recall = tp_opt / (tp_opt + fn_opt) if (tp_opt + fn_opt) > 0 else 0\n",
        "optimized_precision = tp_opt / (tp_opt + fp_opt) if (tp_opt + fp_opt) > 0 else 0\n",
        "optimized_f1 = 2 * (optimized_precision * optimized_recall) / (optimized_precision + optimized_recall) if (optimized_precision + optimized_recall) > 0 else 0\n",
        "\n",
        "print(f\"\\nüìä OPTIMIZED PERFORMANCE:\")\n",
        "print(f\"  ‚Ä¢ Threshold: {optimal_threshold:.3f}\")\n",
        "print(f\"  ‚Ä¢ Recall:    {optimized_recall:.3f} ({optimized_recall*100:.1f}% of leavers detected)\")\n",
        "print(f\"  ‚Ä¢ Precision: {optimized_precision:.3f}\")\n",
        "print(f\"  ‚Ä¢ F1-Score:  {optimized_f1:.3f}\")\n",
        "print(f\"  ‚Ä¢ True Positives:  {tp_opt}\")\n",
        "print(f\"  ‚Ä¢ False Negatives: {fn_opt}\")\n",
        "\n",
        "# BUSINESS IMPACT ANALYSIS\n",
        "print(f\"\\nüí∞ BUSINESS IMPACT ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Cost assumptions\n",
        "AVERAGE_REPLACEMENT_COST = 50000\n",
        "TRAINING_COST_PER_EMPLOYEE = 5000\n",
        "\n",
        "# Calculate business impact with optimized model\n",
        "risk_scores_optimized = (y_pred_proba >= optimal_threshold).astype(int)\n",
        "high_risk_employees = risk_scores_optimized.sum()\n",
        "\n",
        "# Assuming 70% of identified high-risk employees can be retained with interventions\n",
        "retention_success_rate = 0.70\n",
        "potential_retentions = int(high_risk_employees * retention_success_rate)\n",
        "\n",
        "# Cost savings calculation\n",
        "cost_savings = potential_retentions * AVERAGE_REPLACEMENT_COST\n",
        "\n",
        "print(f\"  ‚Ä¢ Potential Retentions (assuming {retention_success_rate*100}% success rate): {potential_retentions} employees\")\n",
        "print(f\"  ‚Ä¢ Estimated Cost Savings: ${cost_savings:,.2f}\")\n",
        "\n",
        "# Additional business impact metrics\n",
        "# Cost of false positives (interventions on employees who wouldn't leave)\n",
        "cost_of_false_positives = fp_opt * TRAINING_COST_PER_EMPLOYEE\n",
        "print(f\"  ‚Ä¢ Estimated Cost of False Positives: ${cost_of_false_positives:,.2f}\")\n",
        "\n",
        "# Cost of false negatives (leavers not identified)\n",
        "# Assuming average loss per leaver is the replacement cost\n",
        "cost_of_false_negatives = fn_opt * AVERAGE_REPLACEMENT_COST\n",
        "print(f\"  ‚Ä¢ Estimated Cost of False Negatives: ${cost_of_false_negatives:,.2f}\")\n",
        "\n",
        "# Net savings\n",
        "net_savings = cost_savings - cost_of_false_positives\n",
        "print(f\"  ‚Ä¢ Estimated Net Savings: ${net_savings:,.2f}\")\n",
        "\n",
        "\n",
        "# DEPLOYMENT CONSIDERATIONS (Placeholder - actual deployment would involve more steps)\n",
        "print(f\"\\n‚öôÔ∏è DEPLOYMENT CONSIDERATIONS\")\n",
        "print(\"=\" * 60)\n",
        "print(\"  ‚Ä¢ The trained model and scaler can be saved for deployment.\")\n",
        "print(\"  ‚Ä¢ A real-time or batch scoring process would be needed to apply the model to new data.\")\n",
        "print(\"  ‚Ä¢ Integration with HR systems would be required for automated risk assessment.\")\n",
        "print(\"  ‚Ä¢ Ongoing monitoring and retraining of the model will be necessary.\")\n",
        "\n",
        "print(\"\\n‚úÖ Performance optimization and business impact analysis completed.\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ NOTEBOOK 5: PERFORMANCE OPTIMIZATION AND DEPLOYMENT\n",
            "==================================================\n",
            "üì• Loading best model and data...\n",
            "Training set: (1176, 30)\n",
            "Test set: (294, 30)\n",
            "\n",
            "üéØ THRESHOLD OPTIMIZATION FOR MAXIMUM RECALL\n",
            "üîç Threshold Analysis:\n",
            "  ‚Ä¢ Default threshold (0.5): Recall = 1.000\n",
            "  ‚Ä¢ Optimal threshold for 75.0% recall: 0.010\n",
            "\n",
            "üìä OPTIMIZED PERFORMANCE:\n",
            "  ‚Ä¢ Threshold: 0.010\n",
            "  ‚Ä¢ Recall:    1.000 (100.0% of leavers detected)\n",
            "  ‚Ä¢ Precision: 0.160\n",
            "  ‚Ä¢ F1-Score:  0.276\n",
            "  ‚Ä¢ True Positives:  47\n",
            "  ‚Ä¢ False Negatives: 0\n",
            "\n",
            "üí∞ BUSINESS IMPACT ANALYSIS\n",
            "============================================================\n",
            "  ‚Ä¢ Potential Retentions (assuming 70.0% success rate): 205 employees\n",
            "  ‚Ä¢ Estimated Cost Savings: $10,250,000.00\n",
            "  ‚Ä¢ Estimated Cost of False Positives: $1,235,000.00\n",
            "  ‚Ä¢ Estimated Cost of False Negatives: $0.00\n",
            "  ‚Ä¢ Estimated Net Savings: $9,015,000.00\n",
            "\n",
            "‚öôÔ∏è DEPLOYMENT CONSIDERATIONS\n",
            "============================================================\n",
            "  ‚Ä¢ The trained model and scaler can be saved for deployment.\n",
            "  ‚Ä¢ A real-time or batch scoring process would be needed to apply the model to new data.\n",
            "  ‚Ä¢ Integration with HR systems would be required for automated risk assessment.\n",
            "  ‚Ä¢ Ongoing monitoring and retraining of the model will be necessary.\n",
            "\n",
            "‚úÖ Performance optimization and business impact analysis completed.\n"
          ]
        }
      ]
    }
  ]
}